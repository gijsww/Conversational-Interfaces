{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_answer(input_text):\n",
    "    '''function that cleans the answer texts'''\n",
    "    answer = input_text.strip('\\n')\n",
    "    answer = answer.replace('\\n',' ')\n",
    "    return answer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_links(link_list):\n",
    "    '''function that cleans links depending on their target location'''\n",
    "    clean_links = []\n",
    "    \n",
    "    for link in link_list:\n",
    "        if link == None: # no link in answer\n",
    "            clean_links.append(None)\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            link = link['href']\n",
    "            if link[0] == '?': # target is sub page of the faq\n",
    "                f_link = 'https://www.rug.nl/education/faq/' + link\n",
    "                clean_links.append(f_link)\n",
    "            \n",
    "            elif link[0] == '/': # target is sub page of the rug site\n",
    "                f_link = 'https://www.rug.nl' + link\n",
    "                #print(f_link)\n",
    "                clean_links.append(f_link)\n",
    "            \n",
    "            else: # target is a different link\n",
    "                clean_links.append(link)\n",
    "                #print(link)\n",
    "\n",
    "    return clean_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(question_list, answer_list, link_list, url, heading_list):\n",
    "    \"\"\"function retrieves questions and answers from the specific RUG pages\"\"\"\n",
    "    response = get(url)\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    data = html_soup.findAll('div',{'class':'rug-clearfix rug-theme--content rug-mb'})\n",
    "    \n",
    "    for links in data:\n",
    "        link = links.findAll('a')\n",
    "        \n",
    "        for a in link:\n",
    "            if a['href'][0] == \"?\": #check if link is an internal one\n",
    "                current_url = 'https://www.rug.nl/education/faq/'+a['href']\n",
    "                response = get(current_url)\n",
    "                html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                questions = html_soup.find_all(['h2'])\n",
    "                content = html_soup.findAll('div',{'class':'rug-clearfix rug-theme--content rug-mb'})\n",
    "                s_content = html_soup.find('div',{'class':'rug-clearfix rug-theme--content rug-mb'})\n",
    "                \n",
    "                if len(content) == len(questions): #check structure of current questions and answers\n",
    "                    for question, answer in zip(questions, content):      \n",
    "                        if question.text in heading_list: #check if question contains sub questions\n",
    "                            links = answer.find_all('a')\n",
    "\n",
    "                            #access the subquestions\n",
    "                            for a in links:\n",
    "                                q = a.text\n",
    "                                \n",
    "                                if a['href'][0] == \"?\":\n",
    "                                    current_url = 'https://www.rug.nl/education/faq/'+a['href']\n",
    "                                else: \n",
    "                                    current_url = a['href']\n",
    "\n",
    "                                response = get(current_url)\n",
    "                                html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                                ans = html_soup.find('div',{'class':'rug-clearfix rug-theme--content rug-mb'})\n",
    "\n",
    "                                #catch errors when external page is formatted differently\n",
    "                                try:\n",
    "                                    answer = clean_answer(ans.text)\n",
    "                                    ans_link = ans.a\n",
    "                                    link_list.append(ans_link)\n",
    "                                    answer_list.append(answer)\n",
    "                                    question_list.append(q)\n",
    "                                \n",
    "                                #Structure of external url is different\n",
    "                                except(AttributeError, KeyError) as error: \n",
    "                                    ans = html_soup.find(['p'])\n",
    "                                    ans_link = ans.a\n",
    "                                    link_list.append(ans_link)\n",
    "                                    answer = clean_answer(ans.text)\n",
    "                                    answer_list.append(answer)\n",
    "                                    question_list.append(q)\n",
    "                        else:      \n",
    "                            question_list.append(question.text)\n",
    "                            ans_link = answer.a\n",
    "                            link_list.append(ans_link)\n",
    "                            answer = clean_answer(answer.text)\n",
    "                            answer_list.append(answer)   \n",
    "                            \n",
    "                else:\n",
    "                    question = html_soup.find(['h1'])\n",
    "                    question_list.append(question.text)\n",
    "                    ans_link = s_content.a\n",
    "                    link_list.append(ans_link)\n",
    "                    answer = clean_answer(s_content.text)\n",
    "                    answer_list.append(answer)\n",
    "                    \n",
    "            else:\n",
    "                question = a.text\n",
    "                ans_link = links.a\n",
    "                link_list.append(ans_link)\n",
    "                answer = clean_answer(links.text)\n",
    "                question_list.append(question)\n",
    "                answer_list.append(answer)\n",
    "        \n",
    "    return question_list, answer_list, link_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_aiml_file(question_list, answer_list, clean_links):\n",
    "    '''function that automatically generates aiml file from questions, answers and links in answers'''\n",
    "    \n",
    "    with open('aiml_base.aiml', 'w') as f:\n",
    "        for vraag, antwoord, link in zip(question_list, answer_list, clean_links):\n",
    "\n",
    "            if link is not None: # there is a link in the answer\n",
    "                f.write('<category>'+'\\n'+ '<pattern>'+ '\\n'+ vraag+ '\\n'+ '</pattern>'+'\\n'+\n",
    "                '<template>'+ '\\n'+ antwoord + '\\n'+ '<button>' + '\\n' + '<text>' + '\\n'+ 'Klik hier' \n",
    "                + '\\n' + '</text>' + '\\n' + '<url>'+ '\\n' +link+ '\\n' + '</url>' + '\\n' + '</button>' + '\\n' '</template>'+'\\n'+'</category>'+'\\n'+'\\n')\n",
    "\n",
    "            else:\n",
    "                f.write('<category>'+'\\n'+\n",
    "              '<pattern>'+ '\\n'+ vraag+ '\\n'+ '</pattern>'+'\\n'+\n",
    "              '<template>'+ '\\n'+ antwoord+ '\\n'+ '</template>'+'\\n'+\n",
    "              '</category>'+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add headings which contain sub_links to this list\n",
    "heading_list = [\"Aanmelding- en selectieprocedure\",\"Onderwijs - honoursprogramma\",\"Bindend Studieadvies (BSA)\", \n",
    "                \"Studeren met een functiebeperking\", \"Studiedips en andere studieproblemen.\", \"Studiekeuze\", \n",
    "                \"Studievertraging\", \"Honours College\", \"Academische ontwikkeling\", \"Titulatuur / graden\", \"Alumni\"] \n",
    "\n",
    "#currently contains 3 start pages: naast je studie, begeleiding and studieloopbaan \n",
    "url_list = ['https://www.rug.nl/education/faq/?tcid=verint_3_7412_7412', 'https://www.rug.nl/education/faq/?tcid=verint_3_7398_7398', \n",
    "            'https://www.rug.nl/education/faq/?tcid=verint_3_7399_7399']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list = []\n",
    "answer_list = []\n",
    "link_list = []\n",
    "\n",
    "for url in url_list:\n",
    "    question_list, answer_list, link_list = retrieve_data(question_list, answer_list, link_list, url, heading_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_links = clean_links(link_list)\n",
    "write_aiml_file(question_list, answer_list, clean_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect questions and answers\n",
    "for vraag, antwoord in zip(question_list, answer_list):\n",
    "    print(vraag,antwoord,'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
